<!DOCTYPE html>
<!-- saved from url=(0063)https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/ -->
<html class="theme-next mist use-motion" lang=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="generator" content="Hexo 3.8.0">
  
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="./Spark SortShuffleWriter 原理 _ 学习笔记_files/jquery.fancybox.css" rel="stylesheet" type="text/css">







<link href="./Spark SortShuffleWriter 原理 _ 学习笔记_files/font-awesome.min.css" rel="stylesheet" type="text/css">

<link href="./Spark SortShuffleWriter 原理 _ 学习笔记_files/main.css" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="https://zhmin.github.io/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="https://zhmin.github.io/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="https://zhmin.github.io/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="https://zhmin.github.io/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="spark, shuffle, SortShuffleWriter,">










<meta name="description" content="Spark SortShuffleWriter 原理在进行shuffle之前，map端会先将数据进行排序。排序的规则，根据不同的场景，会分为两种。首先会根据Key将元素分成不同的partition。第一种只需要保证元素的partitionId排序，但不会保证同一个partitionId的内部排序。第二种是既保证元素的partitionId排序，也会保证同一个partitionId的内部排序。 因为">
<meta name="keywords" content="spark, shuffle, SortShuffleWriter">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark SortShuffleWriter 原理">
<meta property="og:url" content="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/index.html">
<meta property="og:site_name" content="学习笔记">
<meta property="og:description" content="Spark SortShuffleWriter 原理在进行shuffle之前，map端会先将数据进行排序。排序的规则，根据不同的场景，会分为两种。首先会根据Key将元素分成不同的partition。第一种只需要保证元素的partitionId排序，但不会保证同一个partitionId的内部排序。第二种是既保证元素的partitionId排序，也会保证同一个partitionId的内部排序。 因为">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://www.plantuml.com/plantuml/svg/ut8eBaaiAYdDpU7YIiv9B2vM22_AB4bCoaaD00fdbcJcvwMc12Hc5Zddv-Ia9eFuK7L8yeu51QbvAVvvEPM-YGMOqY3jJgLfQQb5N5m4JLUmgT7LnMquwVgHRNS0cWJoAW00">
<meta property="og:image" content="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/spark-sort-shuffle-writer.svg">
<meta property="og:updated_time" content="2019-02-27T13:35:01.535Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark SortShuffleWriter 原理">
<meta name="twitter:description" content="Spark SortShuffleWriter 原理在进行shuffle之前，map端会先将数据进行排序。排序的规则，根据不同的场景，会分为两种。首先会根据Key将元素分成不同的partition。第一种只需要保证元素的partitionId排序，但不会保证同一个partitionId的内部排序。第二种是既保证元素的partitionId排序，也会保证同一个partitionId的内部排序。 因为">
<meta name="twitter:image" content="http://www.plantuml.com/plantuml/svg/ut8eBaaiAYdDpU7YIiv9B2vM22_AB4bCoaaD00fdbcJcvwMc12Hc5Zddv-Ia9eFuK7L8yeu51QbvAVvvEPM-YGMOqY3jJgLfQQb5N5m4JLUmgT7LnMquwVgHRNS0cWJoAW00">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/">





  <title>Spark SortShuffleWriter 原理 | 学习笔记</title>
  








<style type="text/css">.v{font-size:16px;text-align:left}.v *{-webkit-box-sizing:border-box;box-sizing:border-box;line-height:2;color:#555;-webkit-transition:all .3s ease;transition:all .3s ease}.v hr{margin:.825em 0;border-color:#f6f6f6;border-style:dashed}.v.hide-avatar .vimg{display:none}.v a{position:relative;cursor:pointer;color:#1abc9c;display:inline-block}.v a:before{content:"";position:absolute;width:0;right:0;bottom:0;height:1px;background:#1abc9c;-webkit-transition:width .3s ease;transition:width .3s ease}.v a:hover{color:#d7191a}.v a:hover:before{width:100%;left:0;right:auto}.v code,.v pre{background-color:#f6f6f6;color:#555;padding:.2em .4em;border-radius:3px;font-size:85%;margin:0;font-family:Source Code Pro,courier new,Input Mono,PT Mono,SFMono-Regular,Consolas,Monaco,Menlo,PingFang SC,Liberation Mono,Microsoft YaHei,Courier，monospace}.v pre{padding:10px;overflow:auto;line-height:1.45}.v pre code{padding:0;background:transparent;white-space:pre-wrap;word-break:keep-all}.v blockquote{color:#666;margin:.5em 0;padding:0 0 0 1em;border-left:8px solid hsla(0,0%,93%,.5)}.v .vinput{border:none;resize:none;outline:none;padding:10px 5px;max-width:100%;font-size:.775em}.v input[type=checkbox],.v input[type=radio]{display:inline-block;vertical-align:middle;margin-top:-2px}.v .vwrap{border:1px solid #f0f0f0;border-radius:4px;margin-bottom:10px;overflow:hidden;position:relative;padding:10px}.v .vwrap input{background:transparent}.v .vwrap .vedit{position:relative;padding-top:10px}.v .vwrap .vedit .vctrl{text-align:right;font-size:12px}.v .vwrap .vedit .vctrl span{padding:10px;display:inline-block;vertical-align:middle;cursor:pointer}.v .vwrap .vedit .vemojis{display:none;font-size:18px;text-align:justify;max-height:145px;overflow:auto;margin-bottom:10px;-webkit-box-shadow:0 0 1px #f0f0f0;box-shadow:0 0 1px #f0f0f0}.v .vwrap .vedit .vemojis i{font-style:normal;padding:7px 0;width:38px;cursor:pointer;text-align:center;display:inline-block;vertical-align:middle}.v .vwrap .vedit .vpreview{padding:7px;-webkit-box-shadow:0 0 1px #f0f0f0;box-shadow:0 0 1px #f0f0f0}.v .vwrap .vedit .vpreview frame,.v .vwrap .vedit .vpreview iframe,.v .vwrap .vedit .vpreview img{max-width:100%;border:none}.v .vwrap .vheader .vinput{width:33.33%;border-bottom:1px dashed #dedede}.v .vwrap .vheader.item2 .vinput{width:50%}.v .vwrap .vheader.item1 .vinput{width:100%}.v .vwrap .vheader .vinput:focus{border-bottom-color:#eb5055}@media screen and (max-width:520px){.v .vwrap .vheader.item2 .vinput,.v .vwrap .vheader .vinput{width:100%}}.v .vwrap .vcontrol{font-size:0;padding-top:15px}.v .vwrap .vcontrol .col{display:inline-block;font-size:16px;vertical-align:middle;color:#ccc}.v .vwrap .vcontrol .col.text-right{text-align:right}.v .vwrap .vcontrol .col svg{margin-right:2px;overflow:hidden;fill:currentColor;vertical-align:middle}.v .vwrap .vcontrol .col.col-20{width:20%}.v .vwrap .vcontrol .col.col-40{width:40%}.v .vwrap .vcontrol .col.col-60{width:60%}.v .vwrap .vcontrol .col.col-80{width:80%}.v .vwrap .vcontrol .col.split{width:50%}.v .vwrap .vmark{position:absolute;background:rgba(0,0,0,.65);width:100%;height:100%;left:0;top:0}.v .vwrap .vmark .valert{padding-top:3em}.v .vwrap .vmark .valert .vtext{color:#fff;padding:1em 0}.v .vwrap .vmark .valert .vcode{width:4.6875em;border-radius:.3125em;padding:.5em;background:#dedede}.v .vwrap .vmark .valert .vcode:focus{border-color:#3090e4;background-color:#fff}@media screen and (max-width:720px){.v .vwrap .vmark .valert{padding-top:5.5em}.v .vwrap .vmark .valert .vtext{color:#fff;padding:1em 0}}.v .power{color:#999;padding:.5em 0}.v .power,.v .power a{font-size:.75em}.v .vinfo{font-size:0;padding:5px}.v .vinfo .col{font-size:16px;display:inline-block;width:50%;vertical-align:middle}.v .vinfo .vcount .vnum{font-weight:600;font-size:1.25em}.v a{text-decoration:none;color:#555}.v a:hover{color:#222}.v ol,.v ul{padding:0;margin-left:1.25em}.v .txt-center{text-align:center}.v .txt-right{text-align:right}.v .pd5{padding:5px}.v .pd10{padding:10px}.v .veditor{width:100%;min-height:8.75em;font-size:.875em;background:transparent;resize:vertical;-webkit-transition:all .25s ease;transition:all .25s ease}.v .vbtn{-webkit-transition-duration:.4s;transition-duration:.4s;text-align:center;color:#313131;border:1px solid #ededed;border-radius:.3em;display:inline-block;background:#ededed;margin-bottom:0;font-weight:400;vertical-align:middle;-ms-touch-action:manipulation;touch-action:manipulation;cursor:pointer;white-space:nowrap;padding:.5em 1.25em;font-size:.875em;line-height:1.42857143;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;outline:none}.v .vbtn+.vbtn{margin-left:1.25em}.v .vbtn:active,.v .vbtn:hover{color:#3090e4;border-color:#3090e4;background-color:#fff}.v .vempty{padding:1.25em;text-align:center;color:#999}.v .vlist{width:100%}.v .vlist .vcard{padding-top:1.5em;position:relative;display:block}.v .vlist .vcard:after{content:"";clear:both;display:block}.v .vlist .vcard .vimg{width:3.125em;height:3.125em;float:left;border-radius:50%;margin-right:.7525em;border:1px solid #f5f5f5;padding:.125em}@media screen and (max-width:720px){.v .vlist .vcard .vimg{width:2.5em;height:2.5em}}.v .vlist .vcard .vhead{line-height:1.5;margin-top:0}.v .vlist .vcard .vhead .vnick{position:relative;font-size:.875em;font-weight:500;margin-right:.875em;cursor:pointer;color:#1abc9c;text-decoration:none;display:inline-block}.v .vlist .vcard .vhead .vnick:before{content:"";position:absolute;width:0;right:0;bottom:0;height:1px;background:#1abc9c;-webkit-transition:width .3s ease;transition:width .3s ease}.v .vlist .vcard .vhead .vnick:hover{color:#d7191a}.v .vlist .vcard .vhead .vnick:hover:before{width:100%;left:0;right:auto}.v .vlist .vcard .vhead .vsys{display:inline-block;padding:.2em .5em;background:#ededed;color:#b3b1b1;font-size:.75em;border-radius:.2em;margin-right:.3em}@media screen and (max-width:520px){.v .vlist .vcard .vhead .vsys{display:none}}.v .vlist .vcard .vh{overflow:hidden;padding-bottom:.5em;border-bottom:1px dashed #f5f5f5}.v .vlist .vcard .vh .vtime{color:#b3b3b3;font-size:.75em;margin-right:.875em}.v .vlist .vcard .vh .vmeta{line-height:1;position:relative}.v .vlist .vcard .vh .vmeta .vat{font-size:.8125em;color:#ef2f11;cursor:pointer;float:right}.v .vlist .vcard:last-child .vh{border-bottom:none}.v .vlist .vcard .vcontent{word-wrap:break-word;word-break:break-all;text-align:justify;color:#4a4a4a;font-size:.875em;line-height:2;position:relative;margin-bottom:.75em;padding-top:.625em}.v .vlist .vcard .vcontent frame,.v .vlist .vcard .vcontent iframe,.v .vlist .vcard .vcontent img{max-width:100%;border:none}.v .vlist .vcard .vcontent.expand{cursor:pointer;max-height:11.25em;overflow:hidden}.v .vlist .vcard .vcontent.expand:before{display:block;content:"";position:absolute;width:100%;left:0;top:0;bottom:3.15em;pointer-events:none;background:-webkit-gradient(linear,left top,left bottom,from(hsla(0,0%,100%,0)),to(hsla(0,0%,100%,.9)));background:linear-gradient(180deg,hsla(0,0%,100%,0),hsla(0,0%,100%,.9))}.v .vlist .vcard .vcontent.expand:after{display:block;content:"Click on expand";text-align:center;color:#828586;position:absolute;width:100%;height:3.15em;line-height:3.15em;left:0;bottom:0;pointer-events:none;background:hsla(0,0%,100%,.9)}.v .vlist .vcard .vquote{color:#666;margin-top:1em;padding-left:1em;border-left:1px dashed hsla(0,0%,93%,.5)}.v .vlist .vcard .vquote .vimg{width:2.225em;height:2.225em}.v .vpage .vmore{margin:1em 0}.v .clear{content:"";display:block;clear:both}@-webkit-keyframes spin{0%{-webkit-transform:rotate(0deg);transform:rotate(0deg)}to{-webkit-transform:rotate(1turn);transform:rotate(1turn)}}@keyframes spin{0%{-webkit-transform:rotate(0deg);transform:rotate(0deg)}to{-webkit-transform:rotate(1turn);transform:rotate(1turn)}}@-webkit-keyframes pulse{50%{background:#dcdcdc}}@keyframes pulse{50%{background:#dcdcdc}}.v .vloading{position:relative;padding:20px;display:block;height:80px}.v .vloading:before{-webkit-box-sizing:border-box;box-sizing:border-box;content:"";position:absolute;display:inline-block;top:20px;left:50%;margin-left:-20px;width:40px;height:40px;border:6px double #a0a0a0;border-top-color:transparent;border-bottom-color:transparent;border-radius:50%;-webkit-animation:spin 1s infinite linear;animation:spin 1s infinite linear}</style><script src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/fundebug.1.9.0.min.js.下载" apikey="2c7e5b30c7cf402cb7fb35d14b62e7f778babbb70d054160af750065a180fdcd" async="true"></script><style type="text/css">.fancybox-margin{margin-right:17px;}</style></head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="https://zhmin.github.io/" class="brand" rel="start" style="opacity: 1;">
        <span class="logo-line-before"><i class="" style="transform: translateX(100%);"></i></span>
        <span class="site-title" style="opacity: 1; top: 0px;">学习笔记</span>
        <span class="logo-line-after"><i class="" style="transform: translateX(-100%);"></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description" style="opacity: 1; top: 0px;"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home" style="opacity: 1; transform: translateY(0px);">
          <a href="https://zhmin.github.io/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories" style="opacity: 1; transform: translateY(0px);">
          <a href="https://zhmin.github.io/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives" style="opacity: 1; transform: translateY(0px);">
          <a href="https://zhmin.github.io/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block" style="opacity: 1; display: block;">
    <link itemprop="mainEntityOfPage" href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/">

    <span hidden="" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhmin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden="" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="学习笔记">
    </span>

    
      <header class="post-header" style="opacity: 1; display: block; transform: translateY(0px);">

        
        
          <h2 class="post-title" itemprop="name headline">Spark SortShuffleWriter 原理</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-29T22:06:39+08:00">
                2019-01-29
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="https://zhmin.github.io/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/01/29/spark-shuffle-sort-writer-2/" itemprop="commentCount">0</span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/01/29/spark-shuffle-sort-writer-2/" class="leancloud_visitors" data-flag-title="Spark SortShuffleWriter 原理">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors:</span>
               
                 <span class="leancloud-visitors-count">58</span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody" style="opacity: 1; display: block; transform: translateY(0px);">

      
      

      
        <h1 id="Spark-SortShuffleWriter-原理"><a href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#Spark-SortShuffleWriter-%E5%8E%9F%E7%90%86" class="headerlink" title="Spark SortShuffleWriter 原理"></a>Spark SortShuffleWriter 原理</h1><p>在进行shuffle之前，map端会先将数据进行排序。排序的规则，根据不同的场景，会分为两种。首先会根据Key将元素分成不同的partition。第一种只需要保证元素的partitionId排序，但不会保证同一个partitionId的内部排序。第二种是既保证元素的partitionId排序，也会保证同一个partitionId的内部排序。</p>
<p>因为有些shuffle操作涉及到聚合，对于这种需要聚合的操作，使用PartitionedAppendOnlyMap来排序。对于不需要聚合的，则使用PartitionedPairBuffer排序。</p>
<p>两者的关系图如下：</p>
<a href="./Spark SortShuffleWriter 原理 _ 学习笔记_files/ut8eBaaiAYdDpU7YIiv9B2vM22_AB4bCoaaD00fdbcJcvwMc12Hc5Zddv-Ia9eFuK7L8yeu51QbvAVvvEPM-YGMOqY3jJgLfQQb5N5m4JLUmgT7LnMquwVgHRNS0cWJoAW00" class="fancybox fancybox.image" rel="group"><img src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/ut8eBaaiAYdDpU7YIiv9B2vM22_AB4bCoaaD00fdbcJcvwMc12Hc5Zddv-Ia9eFuK7L8yeu51QbvAVvvEPM-YGMOqY3jJgLfQQb5N5m4JLUmgT7LnMquwVgHRNS0cWJoAW00"></a>
<p>WritablePartitionedPairCollection是两者的基类，它提供了排序功能。destructiveSortedWritablePartitionedIterator接收排序规则。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">trait</span> <span class="title">WritablePartitionedPairCollection</span>[<span class="type">K</span>, <span class="type">V</span>] </span>{</span><br><span class="line">    </span><br><span class="line">  <span class="comment">// 进行排序，返回结果</span></span><br><span class="line">  <span class="comment">// keyComparator指定了key的排序规则，默认按照hashCode比较大小</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">partitionedDestructiveSortedIterator</span></span>(keyComparator: <span class="type">Option</span>[<span class="type">Comparator</span>[<span class="type">K</span>]])</span><br><span class="line">    : <span class="type">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">V</span>)]</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">destructiveSortedWritablePartitionedIterator</span></span>(keyComparator: <span class="type">Option</span>[<span class="type">Comparator</span>[<span class="type">K</span>]])</span><br><span class="line">    : <span class="type">WritablePartitionedIterator</span> = {</span><br><span class="line">    <span class="comment">// 获取排序后的结果</span></span><br><span class="line">    <span class="keyword">val</span> it = partitionedDestructiveSortedIterator(keyComparator)</span><br><span class="line">    <span class="comment">// WritablePartitionedIterator提供写入磁盘的方法</span></span><br><span class="line">    <span class="keyword">new</span> <span class="type">WritablePartitionedIterator</span> {</span><br><span class="line">      <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">var</span> cur = <span class="keyword">if</span> (it.hasNext) it.next() <span class="keyword">else</span> <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">writeNext</span></span>(writer: <span class="type">DiskBlockObjectWriter</span>): <span class="type">Unit</span> = {</span><br><span class="line">        writer.write(cur._1._2, cur._2)</span><br><span class="line">        cur = <span class="keyword">if</span> (it.hasNext) it.next() <span class="keyword">else</span> <span class="literal">null</span></span><br><span class="line">      }</span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>(): <span class="type">Boolean</span> = cur != <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">nextPartition</span></span>(): <span class="type">Int</span> = cur._1._1</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>WritablePartitionedPairCollection还提供了封装排序的方法。partitionKeyComparator方法接收一个基于key排序的Comparator， 在包装封装了一层。排序需要先考虑分区，再考虑key排序</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">object</span> <span class="title">WritablePartitionedPairCollection</span> </span>{</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">partitionKeyComparator</span></span>[<span class="type">K</span>](keyComparator: <span class="type">Comparator</span>[<span class="type">K</span>]): <span class="type">Comparator</span>[(<span class="type">Int</span>, <span class="type">K</span>)] = {</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Comparator</span>[(<span class="type">Int</span>, <span class="type">K</span>)] {</span><br><span class="line">     </span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compare</span></span>(a: (<span class="type">Int</span>, <span class="type">K</span>), b: (<span class="type">Int</span>, <span class="type">K</span>)): <span class="type">Int</span> = {</span><br><span class="line">        <span class="keyword">val</span> partitionDiff = a._1 - b._1</span><br><span class="line">        <span class="keyword">if</span> (partitionDiff != <span class="number">0</span>) {</span><br><span class="line">          partitionDiff</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">          keyComparator.compare(a._2, b._2)</span><br><span class="line">        }</span><br><span class="line">      }</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h2 id="PartitionedPairBuffer-原理"><a href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#PartitionedPairBuffer-%E5%8E%9F%E7%90%86" class="headerlink" title="PartitionedPairBuffer 原理"></a>PartitionedPairBuffer 原理</h2><p>当只使用rdd的groupby的方法，那么这里只需要分组，而不需要聚合。这种情况会使用PartitionedPairBuffer排序。首先调用PartitionedPairBuffer的insert方法，向PartitionedPairBuffer添加元素，最后调用partitionedDestructiveSortedIterator获取排序后的结果。</p>
<p>PartitionedPairBuffer的原理很简单，它使用数组保存数据，最后调用Tim排序算法，根据分区索引排序。</p>
<p>数据格式如下：</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--------------------------------------------------------------------------</span><br><span class="line">     AnyRef            |   AnyRef   |       AnyRef           |   AnyRef  |</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">   partitionId, key    |   value    |     partitionId, key   |    value  | </span><br><span class="line">--------------------------------------------------------------------------</span><br></pre></td></tr></tbody></table></figure>
<p>PartitionedPairBuffer使用Array[AnyRef] 数组，AnyRef指向两种格式的数据，一种是(parition, key)的元组， 一种是value。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PartitionedPairBuffer</span> </span>{</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 使用AnyRef数组，保存数据</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> data = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">AnyRef</span>](<span class="number">2</span> * initialCapacity)</span><br><span class="line">    <span class="comment">// 数组目前的索引</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> curSize = <span class="number">0</span></span><br><span class="line">    <span class="comment">// 数组的容量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> capacity = initialCapacity</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 添加数据</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span></span>(partition: <span class="type">Int</span>, key: <span class="type">K</span>, value: <span class="type">V</span>): <span class="type">Unit</span> = {</span><br><span class="line">       <span class="keyword">if</span> (curSize == capacity) {</span><br><span class="line">           <span class="comment">// 增大数组的容量</span></span><br><span class="line">           growArray()</span><br><span class="line">       }</span><br><span class="line">       <span class="comment">// // 存储（partition， key）元素</span></span><br><span class="line">       data(<span class="number">2</span> * curSize) = (partition, key.asInstanceOf[<span class="type">AnyRef</span>])</span><br><span class="line">       <span class="comment">// 写入 value</span></span><br><span class="line">       data(<span class="number">2</span> * curSize + <span class="number">1</span>) = value.asInstanceOf[<span class="type">AnyRef</span>]</span><br><span class="line">       curSize += <span class="number">1</span></span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>partitionedDestructiveSortedIterator使用了TimSort算法。TimSort的 定义在org.apache.spark.util.collection包里，具体原理可以搜索。当Sorter排序后，结果仍在存在data数组里。这里封装了data的访问方式，提供了Iterator的遍历。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">partitionedDestructiveSortedIterator</span></span>(keyComparator: <span class="type">Option</span>[<span class="type">Comparator</span>[<span class="type">K</span>]])</span><br><span class="line">    : <span class="type">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">V</span>)] = {</span><br><span class="line">    <span class="comment">// 调用partitionKeyComparator封装keyComparator</span></span><br><span class="line">    <span class="comment">// 如果没有指定keyComparator，则返回只根据分区号排序的Comparator</span></span><br><span class="line">    <span class="keyword">val</span> comparator = keyComparator.map(partitionKeyComparator).getOrElse(partitionComparator)</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Sorter</span>(<span class="keyword">new</span> <span class="type">KVArraySortDataFormat</span>[(<span class="type">Int</span>, <span class="type">K</span>), <span class="type">AnyRef</span>]).sort(data, <span class="number">0</span>, curSize, comparator)</span><br><span class="line">    iterator</span><br><span class="line">  }</span><br></pre></td></tr></tbody></table></figure>
<h2 id="PartitionedAppendOnlyMap-原理"><a href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#PartitionedAppendOnlyMap-%E5%8E%9F%E7%90%86" class="headerlink" title="PartitionedAppendOnlyMap 原理"></a>PartitionedAppendOnlyMap 原理</h2><p>如果shuffle涉及到聚合， 这种情况会使用PartitionedAppendOnlyMap排序。PartitionedAppendOnlyMap提供changeValue方法，添加和合并数据，完成聚合操作。聚合操作的原理可以参见这篇博客  <a href="https://zhmin.github.io/2019/01/28/spark-shuffle-aggregator/" title="Spark 聚合原理">Spark 聚合原理</a> 。</p>
<p>PartitionedAppendOnlyMap自己实现了哈希表，采用了二次探测算法避免哈希冲突。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AppendOnlyMap</span>[<span class="type">K</span>, <span class="type">V</span>](<span class="params">initialCapacity: <span class="type">Int</span> = 64</span>) </span>{</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 因为一条数据，占用array的两个位置。所以数组的大小为 数据的容量的两倍</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> data = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">AnyRef</span>](<span class="number">2</span> * capacity)  </span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> capacity = nextPowerOf2(initialCapacity)</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// hash算法，计算出初始地址</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">rehash</span></span>(h: <span class="type">Int</span>): <span class="type">Int</span> = <span class="type">Hashing</span>.murmur3_32().hashInt(h).asInt()</span><br><span class="line">    </span><br><span class="line">  <span class="comment">// 提供修改数据，这里涉及到聚合操作</span></span><br><span class="line">  <span class="comment">// updateFunc函数接收两个参数，第一个参数表示这个位置是否已经有数据</span></span><br><span class="line">  <span class="comment">// 第二个参数表示原有的数据</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">changeValue</span></span>(key: <span class="type">K</span>, updateFunc: (<span class="type">Boolean</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>): <span class="type">V</span> = {</span><br><span class="line">    <span class="keyword">val</span> k = key.asInstanceOf[<span class="type">AnyRef</span>]</span><br><span class="line">    <span class="keyword">if</span> (k.eq(<span class="literal">null</span>)) {</span><br><span class="line">      <span class="keyword">if</span> (!haveNullValue) {</span><br><span class="line">        incrementSize()</span><br><span class="line">      }</span><br><span class="line">      nullValue = updateFunc(haveNullValue, nullValue)</span><br><span class="line">      haveNullValue = <span class="literal">true</span></span><br><span class="line">      <span class="keyword">return</span> nullValue</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 使用二次探测算法，找到数据的位置</span></span><br><span class="line">    <span class="keyword">var</span> pos = rehash(k.hashCode) &amp; mask</span><br><span class="line">    <span class="keyword">var</span> i = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) {</span><br><span class="line">      <span class="keyword">val</span> curKey = data(<span class="number">2</span> * pos)</span><br><span class="line">      <span class="keyword">if</span> (curKey.eq(<span class="literal">null</span>)) {</span><br><span class="line">        <span class="comment">// 如果当前位置没数据，则调用updateFunc函数，返回新的值</span></span><br><span class="line">        <span class="keyword">val</span> newValue = updateFunc(<span class="literal">false</span>, <span class="literal">null</span>.asInstanceOf[<span class="type">V</span>])</span><br><span class="line">        data(<span class="number">2</span> * pos) = k</span><br><span class="line">        data(<span class="number">2</span> * pos + <span class="number">1</span>) = newValue.asInstanceOf[<span class="type">AnyRef</span>]</span><br><span class="line">        incrementSize()</span><br><span class="line">        <span class="keyword">return</span> newValue</span><br><span class="line">      } <span class="keyword">else</span> <span class="keyword">if</span> (k.eq(curKey) || k.equals(curKey)) {</span><br><span class="line">        <span class="comment">// 如果当前位置有数据，则调用updateFunc函数，返回新的值</span></span><br><span class="line">        <span class="keyword">val</span> newValue = updateFunc(<span class="literal">true</span>, data(<span class="number">2</span> * pos + <span class="number">1</span>).asInstanceOf[<span class="type">V</span>])</span><br><span class="line">        data(<span class="number">2</span> * pos + <span class="number">1</span>) = newValue.asInstanceOf[<span class="type">AnyRef</span>]</span><br><span class="line">        <span class="keyword">return</span> newValue</span><br><span class="line">      } <span class="keyword">else</span> {</span><br><span class="line">        <span class="comment">// 更新pos位置直到找到key</span></span><br><span class="line">        <span class="keyword">val</span> delta = i</span><br><span class="line">        pos = (pos + delta) &amp; mask</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">      }</span><br><span class="line">    }</span><br><span class="line">    <span class="literal">null</span>.asInstanceOf[<span class="type">V</span>] <span class="comment">// Never reached but needed to keep compiler happy</span></span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>PartitionedAppendOnlyMap自己使用了数组来实现哈希表，因为它使用了二次探测算法避免哈希冲突，所以有可能数组并没有存储满。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partitionedDestructiveSortedIterator</span></span>(keyComparator: <span class="type">Option</span>[<span class="type">Comparator</span>[<span class="type">K</span>]])</span><br><span class="line">  : <span class="type">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">V</span>)] = {</span><br><span class="line">  <span class="comment">// 如果没有指定keyComparator，则返回只根据分区号排序的Comparator</span></span><br><span class="line">  <span class="keyword">val</span> comparator = keyComparator.map(partitionKeyComparator).getOrElse(partitionComparator)</span><br><span class="line">  <span class="comment">// 调用destructiveSortedIterator方法排序</span></span><br><span class="line">  destructiveSortedIterator(comparator)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">destructiveSortedIterator</span></span>(keyComparator: <span class="type">Comparator</span>[<span class="type">K</span>]): <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">V</span>)] = {</span><br><span class="line">    destroyed = <span class="literal">true</span></span><br><span class="line">    <span class="comment">// data是存储着数据的数组，</span></span><br><span class="line">    <span class="comment">// 这里会剔除空的元素，将非空的元素往前移</span></span><br><span class="line">    <span class="comment">// keyIndex代表着遍历元素的位置，newIndex代表着要移动的目标位置</span></span><br><span class="line">    <span class="keyword">var</span> keyIndex, newIndex = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (keyIndex &lt; capacity) {</span><br><span class="line">      <span class="keyword">if</span> (data(<span class="number">2</span> * keyIndex) != <span class="literal">null</span>) {</span><br><span class="line">        data(<span class="number">2</span> * newIndex) = data(<span class="number">2</span> * keyIndex)</span><br><span class="line">        data(<span class="number">2</span> * newIndex + <span class="number">1</span>) = data(<span class="number">2</span> * keyIndex + <span class="number">1</span>)</span><br><span class="line">        newIndex += <span class="number">1</span></span><br><span class="line">      }</span><br><span class="line">      keyIndex += <span class="number">1</span></span><br><span class="line">    }</span><br><span class="line">    assert(curSize == newIndex + (<span class="keyword">if</span> (haveNullValue) <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>))</span><br><span class="line">    <span class="comment">// 调用Sorter排序</span></span><br><span class="line">    <span class="keyword">new</span> <span class="type">Sorter</span>(<span class="keyword">new</span> <span class="type">KVArraySortDataFormat</span>[<span class="type">K</span>, <span class="type">AnyRef</span>]).sort(data, <span class="number">0</span>, newIndex, keyComparator)</span><br><span class="line">    <span class="comment">// 将结果以迭代器的形式返回</span></span><br><span class="line">    <span class="keyword">new</span> <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">V</span>)] {</span><br><span class="line">      <span class="keyword">var</span> i = <span class="number">0</span></span><br><span class="line">      <span class="keyword">var</span> nullValueReady = haveNullValue</span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>: <span class="type">Boolean</span> = (i &lt; newIndex || nullValueReady)</span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): (<span class="type">K</span>, <span class="type">V</span>) = {</span><br><span class="line">        <span class="keyword">if</span> (nullValueReady) {</span><br><span class="line">          nullValueReady = <span class="literal">false</span></span><br><span class="line">          (<span class="literal">null</span>.asInstanceOf[<span class="type">K</span>], nullValue)</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">          <span class="keyword">val</span> item = (data(<span class="number">2</span> * i).asInstanceOf[<span class="type">K</span>], data(<span class="number">2</span> * i + <span class="number">1</span>).asInstanceOf[<span class="type">V</span>])</span><br><span class="line">          i += <span class="number">1</span></span><br><span class="line">          item</span><br><span class="line">        }</span><br><span class="line">      }</span><br><span class="line">    }</span><br><span class="line">  }</span><br></pre></td></tr></tbody></table></figure>
<h2 id="添加数据"><a href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E6%B7%BB%E5%8A%A0%E6%95%B0%E6%8D%AE" class="headerlink" title="添加数据"></a>添加数据</h2><p>SortShuffleWriter使用ExternalSorter进行排序，ExternalSorter会根据是否需要聚合来选择不同的算法。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">ExternalSorter</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">C</span>] </span>{</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">insertAll</span></span>(records: <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">V</span>]]): <span class="type">Unit</span> = {</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> stop combining if we find that the reduction factor isn't high</span></span><br><span class="line">    <span class="keyword">val</span> shouldCombine = aggregator.isDefined</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (shouldCombine) {</span><br><span class="line">      <span class="comment">// 涉及到聚合，使用PartitionedAppendOnlyMap算法</span></span><br><span class="line">      <span class="keyword">val</span> mergeValue = aggregator.get.mergeValue</span><br><span class="line">      <span class="keyword">val</span> createCombiner = aggregator.get.createCombiner</span><br><span class="line">      <span class="keyword">var</span> kv: <span class="type">Product2</span>[<span class="type">K</span>, <span class="type">V</span>] = <span class="literal">null</span></span><br><span class="line">      <span class="comment">// 构造聚合函数，如果有旧有值，则调用聚合的mergeValue合并值。否则调用createCombiner实例combiner</span></span><br><span class="line">      <span class="keyword">val</span> update = (hadValue: <span class="type">Boolean</span>, oldValue: <span class="type">C</span>) =&gt; {</span><br><span class="line">        <span class="keyword">if</span> (hadValue) mergeValue(oldValue, kv._2) <span class="keyword">else</span> createCombiner(kv._2)</span><br><span class="line">      }</span><br><span class="line">      <span class="keyword">while</span> (records.hasNext) {</span><br><span class="line">        addElementsRead()</span><br><span class="line">        kv = records.next()</span><br><span class="line">        <span class="comment">// 调用getPartition根据key，获得partitionId， 添加到map里</span></span><br><span class="line">        map.changeValue((getPartition(kv._1), kv._1), update)</span><br><span class="line">        <span class="comment">// 检测是否触发spill</span></span><br><span class="line">        maybeSpillCollection(usingMap = <span class="literal">true</span>)</span><br><span class="line">      }</span><br><span class="line">    } <span class="keyword">else</span> { </span><br><span class="line">      <span class="comment">// 没有涉及到聚合，使用PartitionedPairBuffer算法</span></span><br><span class="line">      <span class="keyword">while</span> (records.hasNext) {</span><br><span class="line">        addElementsRead()</span><br><span class="line">        <span class="keyword">val</span> kv = records.next()</span><br><span class="line">        buffer.insert(getPartition(kv._1), kv._1, kv._2.asInstanceOf[<span class="type">C</span>])</span><br><span class="line">        <span class="comment">// 检测是否触发spill</span></span><br><span class="line">        maybeSpillCollection(usingMap = <span class="literal">false</span>)</span><br><span class="line">      }</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h2 id="溢写文件"><a href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E6%BA%A2%E5%86%99%E6%96%87%E4%BB%B6" class="headerlink" title="溢写文件"></a>溢写文件</h2><p>上面的maybeSpillCollection方法，当数据过多时，会触发溢写。溢写由spill方法负责，它会将已添加的数据进行排序。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">maybeSpillCollection</span></span>(usingMap: <span class="type">Boolean</span>): <span class="type">Unit</span> = {</span><br><span class="line">    <span class="keyword">var</span> estimatedSize = <span class="number">0</span>L</span><br><span class="line">    <span class="keyword">if</span> (usingMap) {</span><br><span class="line">      <span class="comment">// 获取map的大小</span></span><br><span class="line">      estimatedSize = map.estimateSize()</span><br><span class="line">      <span class="comment">// 触发spill过程</span></span><br><span class="line">      <span class="keyword">if</span> (maybeSpill(map, estimatedSize)) {</span><br><span class="line">        map = <span class="keyword">new</span> <span class="type">PartitionedAppendOnlyMap</span>[<span class="type">K</span>, <span class="type">C</span>]</span><br><span class="line">      }</span><br><span class="line">    } <span class="keyword">else</span> {</span><br><span class="line">      <span class="comment">// 获取buffer的大小</span></span><br><span class="line">      estimatedSize = buffer.estimateSize()</span><br><span class="line">      <span class="comment">// 触发spill过程</span></span><br><span class="line">      <span class="keyword">if</span> (maybeSpill(buffer, estimatedSize)) {</span><br><span class="line">        buffer = <span class="keyword">new</span> <span class="type">PartitionedPairBuffer</span>[<span class="type">K</span>, <span class="type">C</span>]</span><br><span class="line">      }</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line"></span><br><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">maybeSpill</span></span>(collection: <span class="type">C</span>, currentMemory: <span class="type">Long</span>): <span class="type">Boolean</span> = {</span><br><span class="line">    <span class="keyword">var</span> shouldSpill = <span class="literal">false</span></span><br><span class="line">    <span class="comment">// 每隔32条数据，检查是否当前使用内存超过限制</span></span><br><span class="line">    <span class="keyword">if</span> (elementsRead % <span class="number">32</span> == <span class="number">0</span> &amp;&amp; currentMemory &gt;= myMemoryThreshold) {</span><br><span class="line">      <span class="comment">// 申请2倍内存</span></span><br><span class="line">      <span class="keyword">val</span> amountToRequest = <span class="number">2</span> * currentMemory - myMemoryThreshold</span><br><span class="line">      <span class="keyword">val</span> granted = acquireMemory(amountToRequest)</span><br><span class="line">      myMemoryThreshold += granted</span><br><span class="line">      <span class="comment">// 如果申请之后的内存，仍然不够存储，那么触发spill</span></span><br><span class="line">      shouldSpill = currentMemory &gt;= myMemoryThreshold</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 当内存不足，或者数据大小超过了指定值，则执行spill</span></span><br><span class="line">    shouldSpill = shouldSpill || _elementsRead &gt; numElementsForceSpillThreshold</span><br><span class="line">    <span class="keyword">if</span> (shouldSpill) {</span><br><span class="line">      _spillCount += <span class="number">1</span></span><br><span class="line">      <span class="comment">// 调用spill</span></span><br><span class="line">      spill(collection)</span><br><span class="line">      _elementsRead = <span class="number">0</span></span><br><span class="line">      _memoryBytesSpilled += currentMemory</span><br><span class="line">      <span class="comment">// 释放数据占用的内存</span></span><br><span class="line">      releaseMemory()</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// 返回是否触发了spill</span></span><br><span class="line">    shouldSpill</span><br><span class="line">  }</span><br><span class="line"></span><br><span class="line"><span class="keyword">override</span> <span class="keyword">protected</span>[<span class="keyword">this</span>] <span class="function"><span class="keyword">def</span> <span class="title">spill</span></span>(collection: <span class="type">WritablePartitionedPairCollection</span>[<span class="type">K</span>, <span class="type">C</span>]): <span class="type">Unit</span> = {</span><br><span class="line">    <span class="comment">// 调用destructiveSortedWritablePartitionedIterator获取排序后的结果</span></span><br><span class="line">    <span class="keyword">val</span> inMemoryIterator = collection.destructiveSortedWritablePartitionedIterator(comparator)</span><br><span class="line">    <span class="comment">// 将排序后的结果写入文件</span></span><br><span class="line">    <span class="keyword">val</span> spillFile = spillMemoryIteratorToDisk(inMemoryIterator)</span><br><span class="line">    <span class="comment">// 记录文件</span></span><br><span class="line">    spills += spillFile</span><br><span class="line">  }</span><br></pre></td></tr></tbody></table></figure>
<p>溢写的结果由SpilledFile表示，它有下列属性描述数据的信息：</p>
<ul>
<li>file， 溢写的文件</li>
<li>elementsPerPartition : Array[Long] ， 代表每个分区对应的数据条数</li>
</ul>
<h2 id="排序原理"><a href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E6%8E%92%E5%BA%8F%E5%8E%9F%E7%90%86" class="headerlink" title="排序原理"></a>排序原理</h2><p>上面通过WritablePartitionedPairCollection获取排序结果，它的destructiveSortedWritablePartitionedIterator方法接收了排序参数comparator。根据是否需要对key排序，comparator的原理不同。</p>
<h3 id="指定key排序"><a href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E6%8C%87%E5%AE%9Akey%E6%8E%92%E5%BA%8F" class="headerlink" title="指定key排序"></a>指定key排序</h3><p>如果rdd指定了order，那么排序会保证partitionId排序，并且也会保证同一个partitionId的内部排序。</p>
<p>这里比较的数据格式为（partitionId, key）</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partitionKeyComparator</span></span>[<span class="type">K</span>](keyComparator: <span class="type">Comparator</span>[<span class="type">K</span>]): <span class="type">Comparator</span>[(<span class="type">Int</span>, <span class="type">K</span>)] = {</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Comparator</span>[(<span class="type">Int</span>, <span class="type">K</span>)] {</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compare</span></span>(a: (<span class="type">Int</span>, <span class="type">K</span>), b: (<span class="type">Int</span>, <span class="type">K</span>)): <span class="type">Int</span> = {</span><br><span class="line">      <span class="comment">// 优先比较partition</span></span><br><span class="line">      <span class="keyword">val</span> partitionDiff = a._1 - b._1</span><br><span class="line">      <span class="keyword">if</span> (partitionDiff != <span class="number">0</span>) {</span><br><span class="line">        partitionDiff</span><br><span class="line">      } <span class="keyword">else</span> {</span><br><span class="line">        <span class="comment">// 如果partition相等，则继续比较key</span></span><br><span class="line">        keyComparator.compare(a._2, b._2)</span><br><span class="line">      }</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>keyComparator指定了Key的排序规则，在ExternalSorter里定义。这里是比较了两个的hashCode。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> keyComparator: <span class="type">Comparator</span>[<span class="type">K</span>] = ordering.getOrElse(<span class="keyword">new</span> <span class="type">Comparator</span>[<span class="type">K</span>] {</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compare</span></span>(a: <span class="type">K</span>, b: <span class="type">K</span>): <span class="type">Int</span> = {</span><br><span class="line">    <span class="keyword">val</span> h1 = <span class="keyword">if</span> (a == <span class="literal">null</span>) <span class="number">0</span> <span class="keyword">else</span> a.hashCode()</span><br><span class="line">    <span class="keyword">val</span> h2 = <span class="keyword">if</span> (b == <span class="literal">null</span>) <span class="number">0</span> <span class="keyword">else</span> b.hashCode()</span><br><span class="line">    <span class="keyword">if</span> (h1 &lt; h2) <span class="number">-1</span> <span class="keyword">else</span> <span class="keyword">if</span> (h1 == h2) <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">  }</span><br><span class="line">})</span><br></pre></td></tr></tbody></table></figure>
<h3 id="不指定key排序"><a href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E4%B8%8D%E6%8C%87%E5%AE%9Akey%E6%8E%92%E5%BA%8F" class="headerlink" title="不指定key排序"></a>不指定key排序</h3><p>如果rdd没有指定order，则只需要比较partitionId排序，而不需要对同一个partitionId内部排序。</p>
<p>这里比较的数据格式为（partitionId, key）</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partitionComparator</span></span>[<span class="type">K</span>]: <span class="type">Comparator</span>[(<span class="type">Int</span>, <span class="type">K</span>)] = <span class="keyword">new</span> <span class="type">Comparator</span>[(<span class="type">Int</span>, <span class="type">K</span>)] {</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compare</span></span>(a: (<span class="type">Int</span>, <span class="type">K</span>), b: (<span class="type">Int</span>, <span class="type">K</span>)): <span class="type">Int</span> = {</span><br><span class="line">      a._1 - b._1</span><br><span class="line">    }</span><br><span class="line">  }</span><br></pre></td></tr></tbody></table></figure>
<h2 id="读取spill文件"><a href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E8%AF%BB%E5%8F%96spill%E6%96%87%E4%BB%B6" class="headerlink" title="读取spill文件"></a>读取spill文件</h2><p>spill文件首先根据partition分片，每个partitioin分片又被切分成多个batch分片。每个batch分片，存储了多条数据。这里多了个batch分片，是因为DiskBlockObjectWriter的commitAndGet方法触发的，commitAndGet会关闭和新建序列化流。</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">------------------------------------------------------------------------------------</span><br><span class="line">                     parition 0                                  |     partition 1</span><br><span class="line">------------------------------------------------------------------------------------</span><br><span class="line">                batch 0              |       batch 1             |   </span><br><span class="line">-------------------------------------------------------------------------------------</span><br><span class="line">record 0   |  record 2  |  record 3  |</span><br></pre></td></tr></tbody></table></figure>
<p>spill的文件读取由SpillReader负责，SpillReader有几个属性比较重要：</p>
<ul>
<li>partitionId， 当前读取record的所在partition</li>
<li>indexInPartition， 当前读取的record在partition的索引</li>
<li>batchId， 当前读取的record的所在batch</li>
<li>lastPartitionId，下一个record所在的partition</li>
<li>nextPartitionToRead， 要读取的下一个partition</li>
</ul>
<p>访问数据，也是按照partition的顺序遍历的。通过readNextPartition方法，返回单个partition的数据。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readNextPartition</span></span>(): <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]] = <span class="keyword">new</span> <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]] {</span><br><span class="line">  <span class="comment">// 记录当前Iterator的所在partition</span></span><br><span class="line">  <span class="keyword">val</span> myPartition = nextPartitionToRead</span><br><span class="line">  nextPartitionToRead += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>: <span class="type">Boolean</span> = {</span><br><span class="line">    <span class="keyword">if</span> (nextItem == <span class="literal">null</span>) {</span><br><span class="line">      <span class="comment">// 调用SpillReader的readNextItem方法，返回record</span></span><br><span class="line">      nextItem = readNextItem()</span><br><span class="line">      <span class="keyword">if</span> (nextItem == <span class="literal">null</span>) {</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">      }</span><br><span class="line">    }</span><br><span class="line">    assert(lastPartitionId &gt;= myPartition)</span><br><span class="line">    <span class="comment">// 如果下一个要读取的record所在的partition，不在等于当前Iterator的所在partition，</span></span><br><span class="line">    <span class="comment">// 也就是当前partition的数据都已经读完</span></span><br><span class="line">    lastPartitionId == myPartition</span><br><span class="line">  }</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): <span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>] = {</span><br><span class="line">    <span class="keyword">if</span> (!hasNext) {</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NoSuchElementException</span></span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">val</span> item = nextItem</span><br><span class="line">    nextItem = <span class="literal">null</span></span><br><span class="line">    item</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h2 id="合并spill文件"><a href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E5%90%88%E5%B9%B6spill%E6%96%87%E4%BB%B6" class="headerlink" title="合并spill文件"></a>合并spill文件</h2><p>ExternalSorter提供了writePartitionedFile方法合并结果，写入到一个文件中。这里分为两种情况，一种是整个过程数据量比较小，没有发生溢写。另一个是数据量比较大，发生了溢写。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">writePartitionedFile</span></span>(</span><br><span class="line">    blockId: <span class="type">BlockId</span>,</span><br><span class="line">    outputFile: <span class="type">File</span>): <span class="type">Array</span>[<span class="type">Long</span>] = {</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 分区数据对于数据的长度</span></span><br><span class="line">  <span class="keyword">val</span> lengths = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Long</span>](numPartitions)</span><br><span class="line">  <span class="comment">// 写入文件的DiskBlockObjectWriter</span></span><br><span class="line">  <span class="keyword">val</span> writer = blockManager.getDiskWriter(blockId, outputFile, serInstance, fileBufferSize,</span><br><span class="line">    context.taskMetrics().shuffleWriteMetrics)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (spills.isEmpty) {</span><br><span class="line">    <span class="comment">// 没有发生溢写的情况</span></span><br><span class="line">    <span class="keyword">val</span> collection = <span class="keyword">if</span> (aggregator.isDefined) map <span class="keyword">else</span> buffer</span><br><span class="line">    <span class="comment">// 直接容器排序，返回结果</span></span><br><span class="line">    <span class="keyword">val</span> it = collection.destructiveSortedWritablePartitionedIterator(comparator)</span><br><span class="line">    <span class="comment">// 遍历结果</span></span><br><span class="line">    <span class="keyword">while</span> (it.hasNext) {</span><br><span class="line">      <span class="comment">// 获取当前分区</span></span><br><span class="line">      <span class="keyword">val</span> partitionId = it.nextPartition()</span><br><span class="line">      <span class="comment">// 将此分区的数据，都写入到文件中</span></span><br><span class="line">      <span class="keyword">while</span> (it.hasNext &amp;&amp; it.nextPartition() == partitionId) {</span><br><span class="line">        it.writeNext(writer)</span><br><span class="line">      }</span><br><span class="line">      <span class="comment">// 每遍历完一个分区的数据，调用commitAndGet返回FileSegment，返回写入数据的信息</span></span><br><span class="line">      <span class="keyword">val</span> segment = writer.commitAndGet()</span><br><span class="line">      lengths(partitionId) = segment.length</span><br><span class="line">    }</span><br><span class="line">  } <span class="keyword">else</span> {</span><br><span class="line">    <span class="comment">// 发生溢写的情况</span></span><br><span class="line">    <span class="comment">// 调用partitionedIterator返回排序后的数据,</span></span><br><span class="line">    <span class="comment">// 返回的id表示分区号，elements表示对应的数据</span></span><br><span class="line">    <span class="keyword">for</span> ((id, elements) &lt;- <span class="keyword">this</span>.partitionedIterator) {</span><br><span class="line">      <span class="keyword">if</span> (elements.hasNext) {</span><br><span class="line">        <span class="keyword">for</span> (elem &lt;- elements) {</span><br><span class="line">          writer.write(elem._1, elem._2)</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 每遍历完一个分区的数据，就调用commitAndGet方法</span></span><br><span class="line">        <span class="keyword">val</span> segment = writer.commitAndGet()</span><br><span class="line">        lengths(id) = segment.length</span><br><span class="line">      }</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">  writer.close()</span><br><span class="line">  lengths</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>这里调用了partitionedIterator方法排序返回结果，partitionedIterator方法其实是调用了merge方法合并结果。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// spills表示溢写文件，inMemory表示最后一部分存在内存的数据</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(spills: <span class="type">Seq</span>[<span class="type">SpilledFile</span>], inMemory: <span class="type">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">C</span>)])</span><br><span class="line">    : <span class="type">Iterator</span>[(<span class="type">Int</span>, <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]])] = {</span><br><span class="line">  <span class="comment">// SpillReader负责读spill文件</span></span><br><span class="line">  <span class="keyword">val</span> readers = spills.map(<span class="keyword">new</span> <span class="type">SpillReader</span>(_))</span><br><span class="line">  <span class="keyword">val</span> inMemBuffered = inMemory.buffered</span><br><span class="line">  <span class="comment">// 按照分区号遍历数据</span></span><br><span class="line">  (<span class="number">0</span> until numPartitions).iterator.map { p =&gt;</span><br><span class="line">    <span class="keyword">val</span> inMemIterator = <span class="keyword">new</span> <span class="type">IteratorForPartition</span>(p, inMemBuffered)</span><br><span class="line">    <span class="keyword">val</span> iterators = readers.map(_.readNextPartition()) ++ <span class="type">Seq</span>(inMemIterator)</span><br><span class="line">    <span class="keyword">if</span> (aggregator.isDefined) {</span><br><span class="line">      <span class="comment">// 指定了聚合，调用mergeWithAggregation排序</span></span><br><span class="line">      (p, mergeWithAggregation(</span><br><span class="line">        iterators, aggregator.get.mergeCombiners, keyComparator, ordering.isDefined))</span><br><span class="line">    } <span class="keyword">else</span> <span class="keyword">if</span> (ordering.isDefined) {</span><br><span class="line">      <span class="comment">// No aggregator given, but we have an ordering (e.g. used by reduce tasks in sortByKey);</span></span><br><span class="line">     <span class="comment">// 指定了order，调用mergeSort合并排序</span></span><br><span class="line">      (p, mergeSort(iterators, ordering.get))</span><br><span class="line">    } <span class="keyword">else</span> {</span><br><span class="line">      (p, iterators.iterator.flatten)</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>mergeWithAggregation方法的原理是调用了mergeSort方法实现排序。</p>
<p>mergeSort的排序原理采用了并排序的算法，使用PriorityQueue优先队列实现。PriorityQueue存储Iterator，比较大小是将Iterator的第一个数据。每次从最小的Iterator取出数据后，然后将iterator重新插入到PriorityQueue，这样PriorityQueue就会将Iterator重新排序。实例如下图所示，有三部分数据，序列按照从上到下的顺序排列。每一步都会从队列中提取一个最小的元素，并将三部分的数据重新排序</p>
<p><a href="./Spark SortShuffleWriter 原理 _ 学习笔记_files/spark-sort-shuffle-writer.svg" class="fancybox fancybox.image" rel="group"><img src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/spark-sort-shuffle-writer.svg" alt="spark-sort-shuffle-writer"></a></p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">mergeSort</span></span>(iterators: <span class="type">Seq</span>[<span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]]], comparator: <span class="type">Comparator</span>[<span class="type">K</span>])</span><br><span class="line">    : <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]] =</span><br><span class="line">{</span><br><span class="line">  <span class="keyword">val</span> bufferedIters = iterators.filter(_.hasNext).map(_.buffered)</span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">Iter</span> </span>= <span class="type">BufferedIterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]]</span><br><span class="line">  <span class="keyword">val</span> heap = <span class="keyword">new</span> mutable.<span class="type">PriorityQueue</span>[<span class="type">Iter</span>]()(<span class="keyword">new</span> <span class="type">Ordering</span>[<span class="type">Iter</span>] {</span><br><span class="line">    <span class="comment">// Use the reverse of comparator.compare because PriorityQueue dequeues the max</span></span><br><span class="line">    <span class="keyword">override</span> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compare</span></span>(x: <span class="type">Iter</span>, y: <span class="type">Iter</span>): <span class="type">Int</span> = -comparator.compare(x.head._1, y.head._1)</span><br><span class="line">  })</span><br><span class="line">  <span class="comment">// 添加所有的iterator</span></span><br><span class="line">  heap.enqueue(bufferedIters: _*)  <span class="comment">// Will contain only the iterators with hasNext = true</span></span><br><span class="line">  <span class="keyword">new</span> <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]] {</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>: <span class="type">Boolean</span> = !heap.isEmpty</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): <span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>] = {</span><br><span class="line">      <span class="keyword">if</span> (!hasNext) {</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NoSuchElementException</span></span><br><span class="line">      }</span><br><span class="line">      <span class="comment">// 取出最小的iterator</span></span><br><span class="line">      <span class="keyword">val</span> firstBuf = heap.dequeue()</span><br><span class="line">      <span class="comment">// 从iterator中取第一个数据</span></span><br><span class="line">      <span class="keyword">val</span> firstPair = firstBuf.next()</span><br><span class="line">      <span class="keyword">if</span> (firstBuf.hasNext) {</span><br><span class="line">        <span class="comment">// 重新插入到PriorityQueue， 让PriorityQueue重新排序</span></span><br><span class="line">        heap.enqueue(firstBuf)</span><br><span class="line">      }</span><br><span class="line">      firstPair</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="https://zhmin.github.io/tags/spark-shuffle-SortShuffleWriter/" rel="tag"># spark, shuffle, SortShuffleWriter</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="https://zhmin.github.io/2019/01/28/spark-shuffle-aggregator/" rel="next" title="Spark Shuffle 聚合原理">
                <i class="fa fa-chevron-left"></i> Spark Shuffle 聚合原理
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="https://zhmin.github.io/2019/02/13/spark-streaming-receiver/" rel="prev" title="Spark Streaming 数据源读取">
                Spark Streaming 数据源读取 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments v" id="comments" style="opacity: 1; display: block;"><div class="vwrap"><div class="vheader item1"><input name="nick" placeholder="昵称" class="vnick vinput" type="text"></div><div class="vedit"><textarea id="veditor" class="veditor vinput" placeholder="comment here"></textarea><div class="vctrl"><span class="vemoji-btn">表情</span> | <span class="vpreview-btn">预览</span></div><div class="vemojis" style="display:none;"><i name="grinning" title="grinning">😀</i><i name="smiley" title="smiley">😃</i><i name="smile" title="smile">😄</i><i name="grin" title="grin">😁</i><i name="laughing" title="laughing">😆</i><i name="sweat_smile" title="sweat_smile">😅</i><i name="joy" title="joy">😂</i><i name="blush" title="blush">😊</i><i name="innocent" title="innocent">😇</i><i name="wink" title="wink">😉</i><i name="relieved" title="relieved">😌</i><i name="heart_eyes" title="heart_eyes">😍</i><i name="kissing_heart" title="kissing_heart">😘</i><i name="kissing" title="kissing">😗</i><i name="kissing_smiling_eyes" title="kissing_smiling_eyes">😙</i><i name="kissing_closed_eyes" title="kissing_closed_eyes">😚</i><i name="yum" title="yum">😋</i><i name="stuck_out_tongue_winking_eye" title="stuck_out_tongue_winking_eye">😜</i><i name="stuck_out_tongue_closed_eyes" title="stuck_out_tongue_closed_eyes">😝</i><i name="stuck_out_tongue" title="stuck_out_tongue">😛</i><i name="sunglasses" title="sunglasses">😎</i><i name="smirk" title="smirk">😏</i><i name="unamused" title="unamused">😒</i><i name="disappointed" title="disappointed">😞</i><i name="pensive" title="pensive">😔</i><i name="worried" title="worried">😟</i><i name="confused" title="confused">😕</i><i name="persevere" title="persevere">😣</i><i name="confounded" title="confounded">😖</i><i name="tired_face" title="tired_face">😫</i><i name="weary" title="weary">😩</i><i name="angry" title="angry">😠</i><i name="rage" title="rage">😡</i><i name="no_mouth" title="no_mouth">😶</i><i name="neutral_face" title="neutral_face">😐</i><i name="expressionless" title="expressionless">😑</i><i name="hushed" title="hushed">😯</i><i name="frowning" title="frowning">😦</i><i name="anguished" title="anguished">😧</i><i name="open_mouth" title="open_mouth">😮</i><i name="astonished" title="astonished">😲</i><i name="dizzy_face" title="dizzy_face">😵</i><i name="flushed" title="flushed">😳</i><i name="scream" title="scream">😱</i><i name="fearful" title="fearful">😨</i><i name="cold_sweat" title="cold_sweat">😰</i><i name="cry" title="cry">😢</i><i name="disappointed_relieved" title="disappointed_relieved">😥</i><i name="sob" title="sob">😭</i><i name="sweat" title="sweat">😓</i><i name="sleepy" title="sleepy">😪</i><i name="sleeping" title="sleeping">😴</i><i name="mask" title="mask">😷</i><i name="smiling_imp" title="smiling_imp">😈</i><i name="smiley_cat" title="smiley_cat">😺</i><i name="smile_cat" title="smile_cat">😸</i><i name="joy_cat" title="joy_cat">😹</i><i name="heart_eyes_cat" title="heart_eyes_cat">😻</i><i name="smirk_cat" title="smirk_cat">😼</i><i name="kissing_cat" title="kissing_cat">😽</i><i name="scream_cat" title="scream_cat">🙀</i><i name="crying_cat_face" title="crying_cat_face">😿</i><i name="pouting_cat" title="pouting_cat">😾</i><i name="cat" title="cat">🐱</i><i name="mouse" title="mouse">🐭</i><i name="cow" title="cow">🐮</i><i name="monkey_face" title="monkey_face">🐵</i><i name="hand" title="hand">✋</i><i name="fist" title="fist">✊</i><i name="v" title="v">✌️</i><i name="point_up" title="point_up">👆</i><i name="point_down" title="point_down">👇</i><i name="point_left" title="point_left">👈</i><i name="point_right" title="point_right">👉</i><i name="facepunch" title="facepunch">👊</i><i name="wave" title="wave">👋</i><i name="clap" title="clap">👏</i><i name="open_hands" title="open_hands">👐</i><i name="+1" title="+1">👍</i><i name="-1" title="-1">👎</i><i name="ok_hand" title="ok_hand">👌</i><i name="pray" title="pray">🙏</i><i name="ear" title="ear">👂</i><i name="eyes" title="eyes">👀</i><i name="nose" title="nose">👃</i><i name="lips" title="lips">👄</i><i name="tongue" title="tongue">👅</i><i name="heart" title="heart">❤️</i><i name="cupid" title="cupid">💘</i><i name="sparkling_heart" title="sparkling_heart">💖</i><i name="star" title="star">⭐️</i><i name="sparkles" title="sparkles">✨</i><i name="zap" title="zap">⚡️</i><i name="sunny" title="sunny">☀️</i><i name="cloud" title="cloud">☁️</i><i name="snowflake" title="snowflake">❄️</i><i name="umbrella" title="umbrella">☔️</i><i name="coffee" title="coffee">☕️</i><i name="airplane" title="airplane">✈️</i><i name="anchor" title="anchor">⚓️</i><i name="watch" title="watch">⌚️</i><i name="phone" title="phone">☎️</i><i name="hourglass" title="hourglass">⌛️</i><i name="email" title="email">✉️</i><i name="scissors" title="scissors">✂️</i><i name="black_nib" title="black_nib">✒️</i><i name="pencil2" title="pencil2">✏️</i><i name="x" title="x">❌</i><i name="recycle" title="recycle">♻️</i><i name="white_check_mark" title="white_check_mark">✅</i><i name="negative_squared_cross_mark" title="negative_squared_cross_mark">❎</i><i name="m" title="m">Ⓜ️</i><i name="i" title="i">ℹ️</i><i name="tm" title="tm">™️</i><i name="copyright" title="copyright">©️</i><i name="registered" title="registered">®️</i></div><div class="vinput vpreview" style="display:none;"></div></div><div class="vcontrol"><div class="col col-20" title="Markdown is supported"><a href="https://segmentfault.com/markdown" target="_blank"><svg class="markdown" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M14.85 3H1.15C.52 3 0 3.52 0 4.15v7.69C0 12.48.52 13 1.15 13h13.69c.64 0 1.15-.52 1.15-1.15v-7.7C16 3.52 15.48 3 14.85 3zM9 11H7V8L5.5 9.92 4 8v3H2V5h2l1.5 2L7 5h2v6zm2.99.5L9.5 8H11V5h2v3h1.5l-2.51 3.5z"></path></svg></a></div><div class="col col-80 text-right"><button type="button" title="Cmd|Ctrl+Enter" class="vsubmit vbtn">回复</button></div></div><div style="display:none;" class="vmark"></div></div><div class="vinfo" style="display:none;"><div class="vcount col"></div></div><div class="vlist"></div><div class="vempty" style="display:block;">快来做第一个评论的人吧~</div><div class="vpage txt-center"></div><div class="info"><div class="power txt-right">Powered By <a href="https://valine.js.org/" target="_blank">Valine</a><br>v1.3.10</div></div></div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first" style="width: 100%; top: 0px; transform: rotateZ(0deg); opacity: 1; left: 0px;"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle" style="width: 100%; opacity: 1; left: 0px; top: 0px; transform: rotateZ(0deg);"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last" style="width: 100%; top: 0px; transform: rotateZ(0deg); opacity: 1; left: 0px;"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel" style="">
        <div class="site-overview" style="max-height: 831.5px;">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">zhmin</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="https://zhmin.github.io/archives/">
              
                  <span class="site-state-item-count">51</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="https://zhmin.github.io/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">48</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/zhmin" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc" style="max-height: 831.5px;">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1 active"><a class="nav-link" href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#Spark-SortShuffleWriter-%E5%8E%9F%E7%90%86"><span class="nav-number">1.</span> <span class="nav-text">Spark SortShuffleWriter 原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#PartitionedPairBuffer-%E5%8E%9F%E7%90%86"><span class="nav-number">1.1.</span> <span class="nav-text">PartitionedPairBuffer 原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#PartitionedAppendOnlyMap-%E5%8E%9F%E7%90%86"><span class="nav-number">1.2.</span> <span class="nav-text">PartitionedAppendOnlyMap 原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E6%B7%BB%E5%8A%A0%E6%95%B0%E6%8D%AE"><span class="nav-number">1.3.</span> <span class="nav-text">添加数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E6%BA%A2%E5%86%99%E6%96%87%E4%BB%B6"><span class="nav-number">1.4.</span> <span class="nav-text">溢写文件</span></a></li><li class="nav-item nav-level-2 active"><a class="nav-link" href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E6%8E%92%E5%BA%8F%E5%8E%9F%E7%90%86"><span class="nav-number">1.5.</span> <span class="nav-text">排序原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E6%8C%87%E5%AE%9Akey%E6%8E%92%E5%BA%8F"><span class="nav-number">1.5.1.</span> <span class="nav-text">指定key排序</span></a></li><li class="nav-item nav-level-3 active active-current"><a class="nav-link" href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E4%B8%8D%E6%8C%87%E5%AE%9Akey%E6%8E%92%E5%BA%8F"><span class="nav-number">1.5.2.</span> <span class="nav-text">不指定key排序</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E8%AF%BB%E5%8F%96spill%E6%96%87%E4%BB%B6"><span class="nav-number">1.6.</span> <span class="nav-text">读取spill文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="https://zhmin.github.io/2019/01/29/spark-shuffle-sort-writer-2/#%E5%90%88%E5%B9%B6spill%E6%96%87%E4%BB%B6"><span class="nav-number">1.7.</span> <span class="nav-text">合并spill文件</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">© <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zhmin</span>

  
</div>











  <script src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/mermaid.min.js.下载"></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({"startOnload":true,"theme":"forest"});
    }
  </script>



<script async="" src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/busuanzi.pure.mini.js.下载"></script>
<span id="busuanzi_container_site_pv" style="display: inline;">
    访问量<span id="busuanzi_value_site_pv">3594</span>
</span>
<span class="post-meta-divider">|</span>
<span id="busuanzi_container_site_uv" style="display: inline;">
  访客数<span id="busuanzi_value_site_uv">954</span>
</span>

        







        
      </div>
    </footer>

    
      <div class="back-to-top back-to-top-on">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/index.js.下载"></script>
  

  
  
    <script type="text/javascript" src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/fastclick.min.js.下载"></script>
  

  
  
    <script type="text/javascript" src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/jquery.lazyload.js.下载"></script>
  

  
  
    <script type="text/javascript" src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/velocity.min.js.下载"></script>
  

  
  
    <script type="text/javascript" src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/velocity.ui.min.js.下载"></script>
  

  
  
    <script type="text/javascript" src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/jquery.fancybox.pack.js.下载"></script>
  


  


  <script type="text/javascript" src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/utils.js.下载"></script>

  <script type="text/javascript" src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/motion.js.下载"></script>



  
  

  
  <script type="text/javascript" src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/scrollspy.js.下载"></script>
<script type="text/javascript" src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/post-details.js.下载"></script>



  


  <script type="text/javascript" src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/bootstrap.js.下载"></script>



  


  




	





  





  










  <script src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/av-min.js.下载"></script>
  <script src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/Valine.min.js.下载"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'iYiPQlDR2X2zg2QIql2UEe2o-gzGzoHsz',
        appKey: 'EW8G4sftwX1pef1zS9EsOeKE',
        placeholder: 'comment here',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  
  <script src="./Spark SortShuffleWriter 原理 _ 学习笔记_files/av-core-mini-0.6.4.js.下载"></script>
  <script>AV.initialize("iYiPQlDR2X2zg2QIql2UEe2o-gzGzoHsz", "EW8G4sftwX1pef1zS9EsOeKE");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  

  

  



</body></html>